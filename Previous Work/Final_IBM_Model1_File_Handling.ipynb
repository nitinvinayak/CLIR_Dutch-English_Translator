{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Files\n",
    "\n",
    "UPDATED_ENGLISH_FILE = 'English_Updated.txt'\n",
    "UPDATED_DUTCH_FILE = 'Dutch_Updated.txt'\n",
    "\n",
    "ENG_TEST_FILE = 'eng.txt'\n",
    "DUTCH_TEST_FILE = 'dutch.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Files\n",
    "\n",
    "PROB_FILE = 'condProb.txt'\n",
    "COUNT_FILE = 'count.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfiles(Eng_File, Dutch_File,no_of_sentences):\n",
    "    \"\"\"\n",
    "    Function to read required number of lines(no_of_sentences) from given text files  \n",
    "    \n",
    "    \"\"\"\n",
    "    e_file = open(Eng_File,'r',encoding = 'utf-8')\n",
    "    d_file = open(Dutch_File,'r',encoding = 'utf-8')\n",
    "    \n",
    "    dutch = d_file.readlines()[:no_of_sentences]\n",
    "    eng = e_file.readlines()[:no_of_sentences]\n",
    "    \n",
    "    return eng, dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_no_of_sentences = len(dutch) # or len(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(l,lang):\n",
    "    \"\"\"\n",
    "    Function to remove punctuation symbols from acquired sentences\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(l)):\n",
    "        l[i] = l[i][:-1].lower()\n",
    "        l[i] = remove_stopwords(l[i],lang)\n",
    "        l[i] = remove_stuff(l[i])\n",
    "    return l\n",
    "\n",
    "def remove_stopwords(l,lang):\n",
    "    eng_sw = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "    dut_sw = ['de', 'en', 'van', 'ik', 'te', 'dat', 'die', 'in', 'een', 'hij', 'het', 'niet', 'zijn', 'is', 'was', 'op', 'aan', 'met', 'als', 'voor', 'had', 'er', 'maar', 'om', 'hem', 'dan', 'zou', 'of', 'wat', 'mijn', 'men', 'dit', 'zo', 'door', 'over', 'ze', 'zich', 'bij', 'ook', 'tot', 'je', 'mij', 'uit', 'der', 'daar', 'haar', 'naar', 'heb', 'hoe', 'heeft', 'hebben', 'deze', 'u', 'want', 'nog', 'zal', 'me', 'zij', 'nu', 'ge', 'geen', 'omdat', 'iets', 'worden', 'toch', 'al', 'waren', 'veel', 'meer', 'doen', 'toen', 'moet', 'ben', 'zonder', 'kan', 'hun', 'dus', 'alles', 'onder', 'ja', 'eens', 'hier', 'wie', 'werd', 'altijd', 'doch', 'wordt', 'wezen', 'kunnen', 'ons', 'zelf', 'tegen', 'na', 'reeds', 'wil', 'kon', 'niets', 'uw', 'iemand', 'geweest', 'andere']\n",
    "    \n",
    "    words = l.split()\n",
    "    s = []\n",
    "    \n",
    "    if lang =='dutch':\n",
    "        for i in words:\n",
    "            if i not in dut_sw:\n",
    "                s.append(i)\n",
    "    elif lang =='eng':\n",
    "        for i in words:\n",
    "            if i not in eng_sw:\n",
    "                s.append(i)\n",
    "    return ' '.join(s)\n",
    "    \n",
    "def remove_stuff(l):\n",
    "    a = [ ':','.' , '\\\\' , '/' , ',' , ';' , '(' , ')' , '\"', \"\\'\",'1','2','3','4','5','6','7','8','9','0','?']\n",
    "    for i in a:\n",
    "        l = l.replace(i, \"\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# After cleaning files\\n\\ndutch2 = remove_punc(dutch)\\neng2 = remove_punc(eng)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# After cleaning files\n",
    "\n",
    "dutch2 = remove_punc(dutch)\n",
    "eng2 = remove_punc(eng)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dutchWords_line_no = defaultdict(set)\\nengWords_line_no = defaultdict(set)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dutchWords_line_no = defaultdict(set)\n",
    "engWords_line_no = defaultdict(set)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_line_no(doc):\n",
    "    dict_lo = defaultdict(set)\n",
    "    for i in range(len(doc)):\n",
    "        t = doc[i].split()\n",
    "        for m in t:\n",
    "            dict_lo[m].add(i)\n",
    "    return dict_lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dutchWords_line_no = assign_line_no(dutch2)\\nengWords_line_no = assign_line_no(eng2)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dutchWords_line_no = assign_line_no(dutch2)\n",
    "engWords_line_no = assign_line_no(eng2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no_of_words_eng = len(engWords_line_no)\\nno_of_words_dutch = len(dutchWords_line_no)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"no_of_words_eng = len(engWords_line_no)\n",
    "no_of_words_dutch = len(dutchWords_line_no)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(no_of_words_eng)\\nprint(no_of_words_dutch)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(no_of_words_eng)\n",
    "print(no_of_words_dutch)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict_dutch(foreign_l,num_dict_dutch):\n",
    "    \"\"\"\n",
    "    Function to create an indexed dictionary of dutch words \n",
    "    \n",
    "    \"\"\"\n",
    "    c=1\n",
    "    for i in foreign_l.keys():\n",
    "        num_dict_dutch[i]=c\n",
    "        c+=1\n",
    "    return num_dict_dutch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(foreign_no_of_words,foreign_l,english_l,num_dict_dutch,num_dict_eng):\n",
    "    \"\"\"\n",
    "    Function to create pairs of English and Dutch words, and initializing their probabilities uniformly\n",
    "    \"\"\"\n",
    "    probabilities = {} # Initializing proablities\n",
    "    counter = 1\n",
    "    index = -1*(foreign_no_of_words)\n",
    "    \n",
    "    num_dict_dutch = make_dict_dutch(foreign_l,num_dict_dutch)\n",
    "\n",
    "    for i in english_l.keys():\n",
    "        for j in foreign_l.keys():\n",
    "            s = i+\"_\"+j\n",
    "            probabilities[s] = 1/foreign_no_of_words\n",
    "\n",
    "        \n",
    "        index,num_dict_eng = write_to_file(probabilities,i,counter,PROB_FILE,foreign_no_of_words,index,num_dict_eng)\n",
    "        counter +=1\n",
    "        probabilities ={}\n",
    "        \n",
    "    return num_dict_dutch, num_dict_eng\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_dict_eng = {}\\nnum_dict_dutch={}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"num_dict_eng = {}\n",
    "num_dict_dutch={}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(probabilities,english_word,counter,file_name,foreign_no_of_words,index,num_dict_eng):\n",
    "    \"\"\"\n",
    "    Function to write probabilities of english-dutch pairs to a file\n",
    "    \"\"\"\n",
    "    file = open(file_name,'a')\n",
    "    num_dict_eng[english_word]=index+foreign_no_of_words\n",
    "    index=index+foreign_no_of_words\n",
    "    for k,v in probabilities.items():\n",
    "        file.write('{0} {1}\\n'.format(k,v))\n",
    "    file.close()\n",
    "    return index, num_dict_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t = time.process_time()\\nprob = initialize(no_of_words_dutch,dutchWords_line_no,engWords_line_no,num_dict_dutch,num_dict_eng)\\nelapsed_time = time.process_time() - t\\nprint(elapsed_time)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"t = time.process_time()\n",
    "prob = initialize(no_of_words_dutch,dutchWords_line_no,engWords_line_no,num_dict_dutch,num_dict_eng)\n",
    "elapsed_time = time.process_time() - t\n",
    "print(elapsed_time)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_probabilities(dutch_sentences, eng_sentences,no_of_sentences,total,num_dict_dutch,num_dict_eng):\n",
    "    \"\"\"\n",
    "    Function to update count for each english-dutch pair\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(no_of_sentences):\n",
    "        \n",
    "        \n",
    "        en = eng_sentences[i]\n",
    "        en_words = en.split()\n",
    "        \n",
    "\n",
    "        du = dutch_sentences[i]\n",
    "        du_words = du.split()\n",
    "        \n",
    "        \n",
    "        #print(du)\n",
    "        #print(en)\n",
    "        #print()\n",
    "\n",
    "        # To already retrieve the count\n",
    "\n",
    "        retrieved_count = {}\n",
    "        retrieved_term_probability = {}\n",
    "\n",
    "        f = open(COUNT_FILE,'r+')\n",
    "        f2 = open(PROB_FILE,'r+')\n",
    "\n",
    "        lines = f.readlines()\n",
    "        lines2 = f2.readlines()\n",
    "\n",
    "        #print(len(lines))\n",
    "        #print(len(lines2))\n",
    "\n",
    "\n",
    "        for e in en_words:\n",
    "\n",
    "            for d in du_words:\n",
    "\n",
    "\n",
    "                eng_line_no = num_dict_eng[e]\n",
    "                dutch_line_no = num_dict_dutch[d]\n",
    "\n",
    "                #print(\"English\",e,eng_line_no)\n",
    "                #print(\"Dutch\",d,dutch_line_no)\n",
    "\n",
    "                line_no = lines[eng_line_no + dutch_line_no-1]\n",
    "                line_no2 = lines2[eng_line_no + dutch_line_no-1]\n",
    "\n",
    "                #print(line_no,\" \",line_no2)\n",
    "                pr = line_no.split()\n",
    "                pr2 = line_no2.split()\n",
    "                #print(pr,pr2)\n",
    "\n",
    "                retrieved_count[pr[0]] = float(pr[1])\n",
    "                retrieved_term_probability[pr2[0]] = float(pr2[1])\n",
    "                #break\n",
    "            #break\n",
    "\n",
    "\n",
    "        f.close()\n",
    "        f2.close()\n",
    "\n",
    "\n",
    "        #stop_2 = input(\"Calculated to Translation Probability & Retrieved Count\")\n",
    "\n",
    "        s_total = {}\n",
    "\n",
    "        for e in en_words:\n",
    "\n",
    "            s_total[e] = 0\n",
    "\n",
    "            for d in du_words:\n",
    "\n",
    "                s = e+'_'+d\n",
    "\n",
    "                #print(s,e)\n",
    "\n",
    "                s_total[e] += retrieved_term_probability[s]\n",
    "\n",
    "\n",
    "        for e in en_words:\n",
    "\n",
    "            for d in du_words:\n",
    "\n",
    "                s = e+'_'+d\n",
    "\n",
    "                retrieved_count[s] += (retrieved_term_probability[s]/s_total[e])\n",
    "\n",
    "                total[d] += (retrieved_term_probability[s]/s_total[e])\n",
    "\n",
    "        # Re-Write into the count_file\n",
    "\n",
    "        #print()\n",
    "        #print(retrieved_count)\n",
    "        #print()\n",
    "        #print(total)\n",
    "\n",
    "        #temp = input(\"Counts modified Again\")\n",
    "\n",
    "        f = open(COUNT_FILE,'r+')\n",
    "\n",
    "        m = f.readlines()\n",
    "\n",
    "        for k,v in retrieved_count.items():\n",
    "\n",
    "            t = k.split('_')\n",
    "\n",
    "            eng_line_no=num_dict_eng[t[0]]\n",
    "            dutch_line_no = num_dict_dutch[t[1]]\n",
    "\n",
    "            final_line_no = eng_line_no + dutch_line_no\n",
    "\n",
    "            m[final_line_no-1] = '{0} {1}\\n'.format(k,v)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        with open(COUNT_FILE,'w') as file:\n",
    "            file.writelines(m)\n",
    "\n",
    "        #s = input(\"Iteration Complete: \")\n",
    "\n",
    "        \n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_function(foreign_l, english_l, dutch_sentences, eng_sentences, no_of_sentences,num_dict_dutch,num_dict_eng,no_of_iterations=1):\n",
    "    \"\"\"\n",
    "    Function to reinitialize total for foreign words and count for eng-dutch pairs. It carries out (no_of_iterations) iterations\n",
    "    It rewrites the translational probabilities back into the CondProb file.\n",
    "    \"\"\"\n",
    "    \n",
    "    for c_i in range(no_of_iterations):\n",
    "        \n",
    "        print(c_i+1)\n",
    "    \n",
    "        count = {}\n",
    "        counter = 1\n",
    "        for i in english_l.keys():\n",
    "            for j in foreign_l.keys():\n",
    "                s = i+\"_\"+j\n",
    "                count[s] = 0\n",
    "            \n",
    "            write_to_file2(count,i,counter,COUNT_FILE,'a')\n",
    "            counter += 1\n",
    "            count = {}\n",
    "        \n",
    "        #stopper = input(\"Count has been initialized\")\n",
    "    \n",
    "    \n",
    "        total = {}\n",
    "    \n",
    "        for k in foreign_l.keys():\n",
    "            total[k] = 0\n",
    "    \n",
    "        #stopper_2 = input(\"Total has been initialized\")\n",
    "        \n",
    "        total = finding_probabilities(dutch_sentences,eng_sentences,no_of_sentences,total,num_dict_dutch,num_dict_eng)\n",
    "    \n",
    "        f = open(COUNT_FILE,'r+')\n",
    "        f2 = open(PROB_FILE,'r+')\n",
    "    \n",
    "        retrieved_count = {}\n",
    "        retrieved_term_probability = {}\n",
    "    \n",
    "        \n",
    "        lines = f.readlines()\n",
    "        lines2 = f2.readlines()\n",
    "        \n",
    "        for e in english_l.keys():\n",
    "            \n",
    "            for d in foreign_l.keys():\n",
    "                \n",
    "                eng_line_no = num_dict_eng[e]\n",
    "                dutch_line_no = num_dict_dutch[d]\n",
    "                \n",
    "                line_no = lines[eng_line_no + dutch_line_no-1]\n",
    "            #line_no2 = lines2[eng_line_no + dutch_line_no-1]\n",
    "                \n",
    "                pr = line_no.split()\n",
    "            #pr2 = line_no2.split()\n",
    "                \n",
    "                retrieved_count[pr[0]] = float(pr[1])\n",
    "            #retrieved_term_probability[pr2[0]] = float(pr2[1])\n",
    "                \n",
    "        f.close()         \n",
    "        f2.close()\n",
    "\n",
    "    \n",
    "    \n",
    "        for d in foreign_l.keys():\n",
    "            for e in english_l.keys():\n",
    "            \n",
    "                s = e+ '_' +d\n",
    "                retrieved_term_probability[s] = retrieved_count[s]/total[d]  \n",
    "            \n",
    "                eng_line_no = num_dict_eng[e]\n",
    "                dutch_line_no = num_dict_dutch[d]\n",
    "            \n",
    "                final_line_no = eng_line_no + dutch_line_no\n",
    "            \n",
    "                lines2[final_line_no-1] = '{0} {1}\\n'.format(s,retrieved_term_probability[s])\n",
    "    \n",
    "        #print(lines2)\n",
    "            \n",
    "        with open(PROB_FILE,'w') as f:\n",
    "            f.writelines(lines2)\n",
    "            \n",
    "        #c = input(\"Iteration Completed\")\n",
    "    \n",
    "        os.remove('count.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file2(probabilities,english_word,counter,file_name,mode = 'a'):\n",
    "    \"\"\"\n",
    "    Function to write the counts into a file\n",
    "    \"\"\"\n",
    "    file = open(file_name,'a') \n",
    "    #file.write(str(counter)+' '+english_word+'\\n')\n",
    "    for k,v in probabilities.items():\n",
    "        file.write('{0} {1}\\n'.format(k,v))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t = time.process_time()\\nrunning_function(dutchWords_line_no,engWords_line_no,dutch2,eng2,total_no_of_sentences)\\nelapsed_time = time.process_time() - t\\nprint(elapsed_time)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"t = time.process_time()\n",
    "running_function(dutchWords_line_no,engWords_line_no,dutch2,eng2,total_no_of_sentences)\n",
    "elapsed_time = time.process_time() - t\n",
    "print(elapsed_time)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_max(foreign_l,english_l,no_of_dutch_words,num_dict_dutch,num_dict_eng):\n",
    "    \"\"\"\n",
    "    Function to retieve the translaton with maximum probabilities for each word to be translated, i.e. to obtain the most probable translation for each word.     \n",
    "    \"\"\"\n",
    "    translation = defaultdict(set)\n",
    "    translation_num = {}\n",
    "    \n",
    "    f = open(PROB_FILE,'r+')\n",
    "    \n",
    "    lines = f.readlines()\n",
    "    \n",
    "    print(len(lines))\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    for e in english_l.keys():\n",
    "        \n",
    "        #print(e,counter)\n",
    "        eng_line_no = num_dict_eng[e]\n",
    "        \n",
    "        translation_num[e] = -1\n",
    "        \n",
    "        min_number = eng_line_no+1\n",
    "        max_number = eng_line_no+no_of_dutch_words+1\n",
    "        \n",
    "        #print(min_number,max_number)\n",
    "        \n",
    "        for i in range(min_number,max_number):\n",
    "            \n",
    "            t = lines[i-1]\n",
    "            \n",
    "            k = t.split()\n",
    "            val = float(k[1])\n",
    "            \n",
    "            if(translation_num[e] < val):\n",
    "                bi_word = k[0].split('_')\n",
    "                dutch_word = bi_word[1]\n",
    "                translation[e] = set()\n",
    "                translation[e].add(dutch_word)\n",
    "                translation_num[e] = val\n",
    "    \n",
    "        counter+=1\n",
    "        \n",
    "    \"\"\"print(translation_num)\n",
    "        \n",
    "    counter = 1\n",
    "    \n",
    "    for e in english_l.keys():\n",
    "        \n",
    "        #print(e,counter)\n",
    "        eng_line_no = num_dict_eng[e]\n",
    "        \n",
    "        m = translation_num[e]\n",
    "        \n",
    "        min_number = eng_line_no+1\n",
    "        max_number = eng_line_no+no_of_dutch_words+1\n",
    "        \n",
    "        print(e)\n",
    "        #print(min_number,max_number)\n",
    "        \n",
    "        for i in range(min_number,max_number):\n",
    "            \n",
    "            t = lines[i-1]\n",
    "            \n",
    "            k = t.split()\n",
    "            val = float(k[1])\n",
    "            \n",
    "            if(m == val):\n",
    "                bi_word = k[0].split('_')\n",
    "                dutch_word = bi_word[1]\n",
    "                print(dutch_word)\n",
    "                translation[e].add(dutch_word)\n",
    "    \n",
    "        counter+=1\n",
    "    print(translation)    \n",
    "    \"\"\"\n",
    "    f.close()\n",
    "    \n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_coefficient(dutchWord_line_no,dut_cleaned,result_dut):\n",
    "    \"\"\"\n",
    "    Function to find Pearson Coefficient\n",
    "    \"\"\"\n",
    "    \n",
    "    resultDutWords_line_no = assign_line_no(result_dut)\n",
    "\n",
    "    tf_of_cleaned = maintain_count(dutchWord_line_no,dut_cleaned)\n",
    "    \n",
    "    tf_of_result = maintain_count(resultDutWords_line_no,result_dut)\n",
    "    \n",
    "    avg_cleaned = statistics.mean(tf_of_cleaned.values())\n",
    "    avg_result = statistics.mean(tf_of_result.values())\n",
    "    \n",
    "    for i in tf_of_cleaned.keys():\n",
    "        \n",
    "        total_sim += ((tf_of_cleaned[i]-avg_cleaned) * (tf_of_result[i] - avg_result))\n",
    "        \n",
    "    stddev_cleaned = statistics.stdev(tf_of_cleaned.values())\n",
    "    stddev_result = statistics.stdev(tf_of_result.values())\n",
    "    \n",
    "    return total_sim/(stddev_cleaned*stddev_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(dutchWord_line_no,dut_cleaned,result_dut):\n",
    "    \"\"\"\n",
    "    Function to find cosine similarity between 2 documents\n",
    "    \n",
    "    Required: Clean test data before calculating cosine_similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    resultDutWords_line_no = assign_line_no(result_dut)\n",
    "\n",
    "    tf_of_cleaned = maintain_count(dutchWord_line_no,dut_cleaned)\n",
    "    \n",
    "    tf_of_result = maintain_count(resultDutWords_line_no,result_dut)\n",
    "    \n",
    "    total_sim = 0\n",
    "    \n",
    "    for i in tf_of_cleaned.keys():\n",
    "        total_sim += tf_of_cleaned[i] * tf_of_result[i]\n",
    "        \n",
    "    return total_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maintain_normalized_tf(doc_dict_line_no,search_file, data_clean):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to find normalized term-frequency of a word in a document.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    og_dutch_tf = {}\n",
    "    \n",
    "    sum_of_tf = 0\n",
    "    \n",
    "    for dword in doc_dict_line_no:                #for each word in the document\n",
    "        dlist=[]\n",
    "        dlist=list(doc_dict_line_no[dword])\n",
    "        count = 0\n",
    "        for i in dlist:\n",
    "            if(dut_cleaned[i].contains(dword)):\n",
    "                count+=1\n",
    "        \n",
    "        og_dutch_tf[dword] = math.log(count)+1\n",
    "        sum_of_tf += pow(og_dutch_tf[dword],2)\n",
    "    \n",
    "    normalized_denom = pow(sum_of_tf,0.5)\n",
    "    \n",
    "    for i in og_dutch_tf.keys():\n",
    "        og_dutch_tf[i] = og_dutch_tf[i]/normalized_denom\n",
    "\n",
    "        \n",
    "    return og_dutch_tf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t = time.process_time()\\ntr = retrieve_max(dutchWords_line_no,engWords_line_no,len(num_dict_dutch))\\nelapsed_time = time.process_time() - t\\nprint(elapsed_time)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"t = time.process_time()\n",
    "tr = retrieve_max(dutchWords_line_no,engWords_line_no,len(num_dict_dutch))\n",
    "elapsed_time = time.process_time() - t\n",
    "print(elapsed_time)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_sentence(eng_sentence, translated_dict,doc_lang):\n",
    "    \"\"\"\n",
    "    Function to translate a sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = \"\"\n",
    "\n",
    "    a = [ ':','.' , '\\\\' , '/' , ',' , ';' , '(' , ')' , '\"', \"\\'\",'1','2','3','4','5','6','7','8','9','0','?']\n",
    "    \n",
    "    for i in eng_sentence:\n",
    "        if i in a:\n",
    "            s+=i\n",
    "            continue\n",
    "            \n",
    "        s += str(tr[i])\n",
    "    \n",
    "    s+='\\n'\n",
    "    \n",
    "    return s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_doc(eng_doc, translated_dict, rewrite_file, doc_lang):\n",
    "    \"\"\"\n",
    "    Function to translate a document.\n",
    "    \"\"\"\n",
    "    \n",
    "    result_doc = []\n",
    "    \n",
    "    for i in eng_doc:\n",
    "        s = produce_sentence(i, translated_dict)\n",
    "        result_doc.append(s)\n",
    "    \n",
    "    with open(rewrite_file,'w') as f:\n",
    "        f.writelines(result_doc)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files():\n",
    "    \"\"\"\n",
    "    Deleting previously present files responsible for maintaining translational probabilities and count.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.remove(PROB_FILE)\n",
    "    except OSError as e:  ## if failed, report it back to the user ##\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    try:\n",
    "        os.remove(COUNT_FILE)\n",
    "    except OSError as e:  ## if failed, report it back to the user ##\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    Eng_File = UPDATED_ENGLISH_FILE\n",
    "    Dutch_File = UPDATED_DUTCH_FILE\n",
    "    \n",
    "    eng_data, dutch_data = readfiles(Eng_File,Dutch_File,100)\n",
    "    \n",
    "    print(\"Files read\")\n",
    "    \n",
    "    # Cleaning Data\n",
    "    \n",
    "    eng_cleaned = remove_punc(eng_data,'eng')\n",
    "    dut_cleaned = remove_punc(dutch_data,'dutch')\n",
    "    \n",
    "    total_no_of_sentences = len(dut_cleaned)\n",
    "    \n",
    "    print(\"Files cleaned\")\n",
    "    \n",
    "    # Making dictionaries\n",
    "    \n",
    "    dutchWords_line_no = assign_line_no(dut_cleaned)\n",
    "    engWords_line_no = assign_line_no(eng_cleaned)\n",
    "    \n",
    "    #print(dutchWords_line_no)\n",
    "    \n",
    "    no_of_words_eng = len(engWords_line_no)\n",
    "    no_of_words_dutch = len(dutchWords_line_no)\n",
    "    \n",
    "    num_dict_eng = {}\n",
    "    num_dict_dutch = {}\n",
    "    \n",
    "    num_dict_dutch,num_dict_eng = initialize(no_of_words_dutch , dutchWords_line_no , engWords_line_no , num_dict_dutch , num_dict_eng)\n",
    "    \n",
    "    #assert(prob==True)\n",
    "    \n",
    "    print(\"Initialization Done\")\n",
    "    \n",
    "    running_function(dutchWords_line_no, engWords_line_no, dut_cleaned , eng_cleaned , total_no_of_sentences, num_dict_dutch,num_dict_eng,5)\n",
    "    \n",
    "    print(\"Model Trained\")\n",
    "    \n",
    "    tr = retrieve_max(dutchWords_line_no,engWords_line_no,len(num_dict_dutch),num_dict_dutch,num_dict_eng)\n",
    "    \n",
    "    #print(tr)\n",
    "    \n",
    "    '''\n",
    "    while(True):\n",
    "    \n",
    "        t = input(\"Do you want to delete all resulting files\")\n",
    "        if (t=='yes' or t == 'y' or t=='Yes' or t == 'Y'):\n",
    "            delete_files()\n",
    "            break\n",
    "        \n",
    "        elif (t=='No' or t=='N' or t=='n' or t=='no'):\n",
    "            break\n",
    "        \n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: count.txt - No such file or directory.\n",
      "Files read\n",
      "Files cleaned\n",
      "Initialization Done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Model Trained\n",
      "487968\n"
     ]
    }
   ],
   "source": [
    "if __name__ ==\"__main__\":\n",
    "    delete_files()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, the remaining stuff:\n",
    "<ul>\n",
    "    <li>README FILE\n",
    "    <li>DOCUMENTATION\n",
    "    <li>SQL INTEGRATION\n",
    "    <li>DICTIONARY FOR STOPWORDS\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
