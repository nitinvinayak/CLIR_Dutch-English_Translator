{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSCpsYMARcIF"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import sqlite3\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBa9nWQCRcIM"
   },
   "outputs": [],
   "source": [
    "# Source Files\n",
    "\n",
    "UPDATED_ENGLISH_FILE = '../Desktop/IR/English_Updated.txt'\n",
    "UPDATED_DUTCH_FILE = '../Desktop/IR/Dutch_Updated.txt'\n",
    "\n",
    "ENG_TEST_FILE = 'eng.txt'\n",
    "DUTCH_TEST_FILE = 'dutch.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZseRGJdRcIQ"
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect('TransProb_100.db')\n",
    "crsr = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "So9Mh2FYRcIU"
   },
   "outputs": [],
   "source": [
    "tr_etof = {}\n",
    "tr_ftoe = {}\n",
    "#total = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDHXqYZFRcIY"
   },
   "outputs": [],
   "source": [
    "# New Files\n",
    "\n",
    "#PROB_FILE = 'condProb.txt'\n",
    "#COUNT_FILE = 'count.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yd88Bn5GRcIc"
   },
   "outputs": [],
   "source": [
    "def EngToDutchStopWords():\n",
    "    eng_sw=['of', 'the', 'I', 'on', 'and', 'would', 'to', 'you', 'a', 'in', 'that', 'as', 'have', 'for', 'be', 'from', 'it', 'at', 'can', 'an', 'has', 'The', 'It', 'is', 'not', 'with', 'We', 'by', 'This', 'we', 'are', 'more', 'our', 'or', 'also', 'these', 'but', 'must']\n",
    "    dut_sw=['van', 'de', 'ik', 'Aan', 'en', 'Zou', 'naar', 'u', 'een', 'in', 'dat', 'als', 'hebben', 'voor', 'worden', 'van', 'het', 'Bij', 'kan', 'een', 'heeft', 'De', 'Het', 'is', 'niet', 'met', 'Wij', 'door', 'Deze', 'wij', 'zijn', 'meer', 'onze', 'of', 'ook', 'deze', 'maar', 'moet']\n",
    "    eng_sw = [i.lower() for i in eng_sw]\n",
    "    dut_sw = [i.lower() for i in dut_sw]\n",
    "    \n",
    "    return (dict(zip(eng_sw, dut_sw)))\n",
    "\n",
    "def DutchToEngStopWords():\n",
    "    eng_sw=['of', 'the', 'I', 'on', 'and', 'would', 'to', 'you', 'a', 'in', 'that', 'as', 'have', 'for', 'be', 'from', 'it', 'at', 'can', 'an', 'has', 'The', 'It', 'is', 'not', 'with', 'We', 'by', 'This', 'we', 'are', 'more', 'our', 'or', 'also', 'these', 'but', 'must']\n",
    "    dut_sw=['van', 'de', 'ik', 'Aan', 'en', 'Zou', 'naar', 'u', 'een', 'in', 'dat', 'als', 'hebben', 'voor', 'worden', 'van', 'het', 'Bij', 'kan', 'een', 'heeft', 'De', 'Het', 'is', 'niet', 'met', 'Wij', 'door', 'Deze', 'wij', 'zijn', 'meer', 'onze', 'of', 'ook', 'deze', 'maar', 'moet']\n",
    "    eng_sw = [i.lower() for i in eng_sw]\n",
    "    dut_sw = [i.lower() for i in dut_sw]\n",
    "    \n",
    "    return (dict(zip( dut_sw,eng_sw)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuz5ir3QVnsP"
   },
   "source": [
    "Function to read required number of lines(no_of_sentences) from given text files  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MATdBVQ2RcIl"
   },
   "outputs": [],
   "source": [
    "def readfiles(Eng_File, Dutch_File,no_of_sentences):\n",
    "    \n",
    "    e_file = open(Eng_File,'r',encoding = 'utf-8')\n",
    "    d_file = open(Dutch_File,'r',encoding = 'utf-8')\n",
    "    \n",
    "    dutch = d_file.readlines()[:no_of_sentences]\n",
    "    eng = e_file.readlines()[:no_of_sentences]\n",
    "    \n",
    "    return eng, dutch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9Yc1m3nVwdi"
   },
   "source": [
    "Function to remove punctuation symbols, stop-words and numbers from acquired sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0xt3_M-RcIv"
   },
   "outputs": [],
   "source": [
    "def remove_punc(l,lang):\n",
    "    \n",
    "    for i in range(len(l)):\n",
    "        l[i] = l[i][:-1].lower()\n",
    "        l[i] = remove_stopwords(l[i],lang)\n",
    "        l[i] = remove_stuff(l[i])\n",
    "    return l\n",
    "\n",
    "def remove_stopwords(l,lang):\n",
    "    eng_sw=['of', 'the', 'i', 'on', 'and', 'would', 'to', 'you', 'a', 'in', 'that', 'as', 'have', 'for', 'be', 'from', 'it', 'at', 'can', 'an', 'has', 'the', 'it', 'is', 'not', 'with', 'we', 'by', 'this', 'we', 'are', 'more', 'our', 'or', 'also', 'these', 'but', 'must']\n",
    "    dut_sw=['van', 'de', 'ik', 'aan', 'en', 'zou', 'naar', 'u', 'een', 'in', 'dat', 'als', 'hebben', 'voor', 'worden', 'van', 'het', 'bij', 'kan', 'een', 'heeft', 'de', 'het', 'is', 'niet', 'met', 'wij', 'door', 'deze', 'wij', 'zijn', 'meer', 'onze', 'of', 'ook', 'deze', 'maar', 'moet']\n",
    "    eng_sw = [i.lower() for i in eng_sw]\n",
    "    dut_sw = [i.lower() for i in dut_sw]\n",
    "    \n",
    "    words = l.split()\n",
    "    s = []\n",
    "    \n",
    "    if lang =='dutch':\n",
    "        for i in words:\n",
    "            if i not in dut_sw:\n",
    "                s.append(i)\n",
    "    elif lang =='eng':\n",
    "        for i in words:\n",
    "            if i not in eng_sw:\n",
    "                s.append(i)\n",
    "    return ' '.join(s)\n",
    "    \n",
    "def remove_stuff(l):\n",
    "    a = [ ':','.' , '\\\\' , '/' , ',' , ';' , '(' , ')' , '\"', \"\\'\",'1','2','3','4','5','6','7','8','9','0','?']\n",
    "    for i in a:\n",
    "        l = l.replace(i, \"\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mt-rAMH4RcI4"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(l,lang):\n",
    "    \"\"\"\n",
    "    Function to remove punctuation symbols from acquired sentences\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(l)):\n",
    "        l[i] = l[i][:-1].lower()\n",
    "        l[i] = remove_stuff(l[i])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "daU9P46zWMyU"
   },
   "source": [
    "Creates an inverted index where each word is matched to all the lines it is present in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z8XGACozRcJA"
   },
   "outputs": [],
   "source": [
    "def assign_line_no(doc):\n",
    "    dict_lo = defaultdict(set)\n",
    "    for i in range(len(doc)):\n",
    "        t = doc[i].split()\n",
    "        for m in t:\n",
    "            dict_lo[m].add(i)\n",
    "    return dict_lo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ne7roI4MWhQP"
   },
   "source": [
    "Function to create an indexed dictionary of dutch words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LVACSLIRcJL"
   },
   "outputs": [],
   "source": [
    "def make_dict_dutch(foreign_l,num_dict_dutch):\n",
    "    \n",
    "    c=1\n",
    "    for i in foreign_l.keys():\n",
    "        num_dict_dutch[i]=c\n",
    "        c+=1\n",
    "    return num_dict_dutch\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98h4h0K2WluP"
   },
   "source": [
    "Function to create pairs of English and Dutch words, and initializing their probabilities uniformly in an SQL Database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRp7RWM-RcJT"
   },
   "outputs": [],
   "source": [
    "def initialize(foreign_no_of_words,foreign_l,english_l,num_dict_dutch,num_dict_eng):\n",
    "    probabilities = {} # Initializing proablities\n",
    "    index = -1*(foreign_no_of_words)\n",
    "    counter = 0\n",
    "    \n",
    "    num_dict_dutch = make_dict_dutch(foreign_l,num_dict_dutch)\n",
    "    init_prob = 1/foreign_no_of_words\n",
    "    \n",
    "    for i in english_l.keys():\n",
    "        num_dict_eng[i]=index+foreign_no_of_words\n",
    "        index=index+foreign_no_of_words\n",
    "    \n",
    "    return num_dict_dutch, num_dict_eng\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGgvR2oVWvde"
   },
   "source": [
    "Updates count variable for each Dutch-English word pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEM0R8tBRcJe"
   },
   "outputs": [],
   "source": [
    "def finding_probabilities(dutch_sentences, eng_sentences,no_of_sentences,total,num_dict_dutch,num_dict_eng,count_file):\n",
    "\n",
    "    for i in range(no_of_sentences):\n",
    "        \n",
    "        \n",
    "        en = eng_sentences[i]\n",
    "        en_words = en.split()\n",
    "        \n",
    "\n",
    "        du = dutch_sentences[i]\n",
    "        du_words = du.split()\n",
    "        \n",
    "\n",
    "        retrieved_count = {}\n",
    "        retrieved_term_probability = {}\n",
    "\n",
    "        for e in en_words:\n",
    "\n",
    "            for d in du_words:\n",
    "\n",
    "                comm = \"select * from TransProb where ENG_WORD= '{0}' AND DUT_WORD= '{1}'\".format(e,d)\n",
    "                com2 = \"select * from Count where ENG_WORD= '{0}' AND DUT_WORD= '{1}'\".format(e,d)\n",
    "                #print(comm)\n",
    "                #print(com2)\n",
    "                \n",
    "                \n",
    "                crsr.execute(comm)\n",
    "                ans = crsr.fetchall()\n",
    "                \n",
    "                crsr.execute(com2)\n",
    "                an2 = crsr.fetchall()\n",
    "                try:\n",
    "                    line_no2= ans[0][0]+'_'+ans[0][1]+' '+str(ans[0][2])\n",
    "                    line_no = an2[0][0]+'_'+an2[0][1]+' '+str(an2[0][2])\n",
    "                except:\n",
    "                    print(line_no2)\n",
    "                pr = line_no.split()\n",
    "                pr2 = line_no2.split()\n",
    "                \n",
    "                #print(pr)\n",
    "                #print(pr2)\n",
    "                retrieved_count[pr[0]] = float(pr[1])\n",
    "                retrieved_term_probability[pr2[0]] = float(pr2[1])\n",
    "              \n",
    "\n",
    "        print(\"Count and Translation probabilities retrieved\")\n",
    "        \n",
    "        #print(retrieved_term_probability)\n",
    "        print()\n",
    "\n",
    "        s_total = {}\n",
    "\n",
    "        for e in en_words:\n",
    "\n",
    "            s_total[e] = 0\n",
    "\n",
    "            for d in du_words:\n",
    "\n",
    "                s = e+'_'+d\n",
    "\n",
    "                s_total[e] += retrieved_term_probability[s]\n",
    "\n",
    "       #print(s_total)\n",
    "        print(\"S_total for each english word done\")\n",
    "                \n",
    "        for e in en_words:\n",
    "\n",
    "            for d in du_words:\n",
    "\n",
    "                s = e+'_'+d\n",
    "\n",
    "                retrieved_count[s] += (retrieved_term_probability[s]/s_total[e])\n",
    "\n",
    "                total[d] += (retrieved_term_probability[s]/s_total[e])\n",
    "\n",
    "        print(\"Counts modified and Total calculated\")\n",
    "        #print(retrieved_count)\n",
    "        print()\n",
    "        print(\"RETRIEVED TP\")\n",
    "        #print(retrieved_term_probability)\n",
    "        print()\n",
    "        \n",
    "        for k,v in retrieved_count.items():\n",
    "            \n",
    "            t = k.split('_')\n",
    "            e = t[0]\n",
    "            d = t[1]\n",
    "            #print(k)\n",
    "            #print(e+\" \"+d)\n",
    "            \n",
    "            command= \"UPDATE Count SET PROBABILITY={0} WHERE ENG_WORD = '{1}' AND DUT_WORD ='{2}' \".format(v,e,d)\n",
    "            #print(command)\n",
    "            crsr.execute(command)\n",
    "                \n",
    "        con.commit()\n",
    "        \n",
    "        print(\"Writeback completed into count file\")\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYgz_j6qXisI"
   },
   "source": [
    "Function to reinitialize total for foreign words and count for eng-dutch pairs. It carries out (no_of_iterations) iterations\n",
    "It rewrites the translational probabilities back into the Database.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Df9A1mdRcJn"
   },
   "outputs": [],
   "source": [
    "def running_function(foreign_l, english_l, dutch_sentences, eng_sentences, no_of_sentences,num_dict_dutch,num_dict_eng,no_of_iterations=10):\n",
    "  \n",
    "    loc =\"\"\n",
    "    \n",
    "    \n",
    "    for c_i in range(no_of_iterations):\n",
    "        \n",
    "        print(c_i+1)\n",
    "        \n",
    "        for i in english_l.keys():\n",
    "            for j in foreign_l.keys():\n",
    "                command= \"UPDATE Count SET PROBABILITY= {0} WHERE ENG_WORD = '{1}' AND DUT_WORD ='{2}' \".format(0,i,j)\n",
    "                #print(command)\n",
    "                crsr.execute(command)\n",
    "            con.commit()\n",
    "            \n",
    "                \n",
    "    \n",
    "        total = {}\n",
    "    \n",
    "        for k in foreign_l.keys():\n",
    "            total[k] = 0\n",
    "    \n",
    "        total = finding_probabilities(dutch_sentences,eng_sentences,no_of_sentences,total,num_dict_dutch,num_dict_eng,loc)\n",
    "    \n",
    "    \n",
    "        print(\"Finding probabilities done, \",c_i)\n",
    "        retrieved_count = {}\n",
    "        retrieved_term_probability = {}\n",
    "    \n",
    "       # print(total)\n",
    "        \n",
    "        \n",
    "        for e in english_l.keys():\n",
    "            \n",
    "            for d in foreign_l.keys():\n",
    "                \n",
    "                dutch_line_no = num_dict_dutch[d]\n",
    "                \n",
    "                com2 = \"select * from Count where ENG_WORD= '{0}' AND DUT_WORD= '{1}'\".format(e,d)\n",
    "                #print(com2)\n",
    "                crsr.execute(com2)\n",
    "                ans = crsr.fetchall()\n",
    "                \n",
    "                try:\n",
    "                    line_no = ans[0][0]+'_'+ans[0][1]+' '+str(ans[0][2])\n",
    "                except:\n",
    "                    print(line_no)\n",
    "                \n",
    "                pr = line_no.split()\n",
    "                \n",
    "                retrieved_count[pr[0]] = float(pr[1])\n",
    "            con.commit()\n",
    "        \n",
    "    \n",
    "\n",
    "        print(\"Counts, retrieved\")\n",
    "        \n",
    "        print()\n",
    "        #print(retrieved_count)\n",
    "        print()\n",
    "    \n",
    "        for d in foreign_l.keys():\n",
    "            for e in english_l.keys():\n",
    "            \n",
    "                s = e+ '_' +d\n",
    "                retrieved_term_probability[s] = retrieved_count[s]/total[d]  \n",
    "                \n",
    "                \n",
    "                command= \"UPDATE TransProb SET PROBABILITY= {0} WHERE ENG_WORD = '{1}' AND DUT_WORD ='{2}' \".format(float(retrieved_term_probability[s]),e,d)\n",
    "                #print(command)\n",
    "                crsr.execute(command)\n",
    "                \n",
    "            con.commit()\n",
    "        \n",
    "        print(\"Translational Probabilites updated\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q39CqBx6XwxG"
   },
   "source": [
    "Function to retrieve the translaton with maximum probabilities for each word to be translated, i.e. to obtain the most probable translation for each word.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AY8jcTj5RcJ7"
   },
   "outputs": [],
   "source": [
    "def retrieve_max(foreign_l,english_l,no_of_dutch_words,num_dict_dutch,num_dict_eng):\n",
    "    \n",
    "    translation_etof = {}\n",
    "    translation_ftoe = {}\n",
    "    \n",
    "    for e in english_l.keys():\n",
    "        \n",
    "        #print(e,counter)\n",
    "        \n",
    "        comm = \"SELECT MAX(PROBABILITY),DUT_WORD From TransProb where ENG_WORD = '{0}'\".format(e)\n",
    "        \n",
    "        crsr.execute(comm)\n",
    "        \n",
    "        ans = crsr.fetchall()\n",
    "         \n",
    "        translation_etof[e] = ans[0][1]\n",
    "        translation_ftoe[ans[0][1]] = e\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    return translation_etof,translation_ftoe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZBGjpJ8ZZgN"
   },
   "source": [
    "Function to find Pearson Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yF2vPbjORcKB"
   },
   "outputs": [],
   "source": [
    "def pearson_coefficient(dut_cleaned,result_dut):\n",
    "       \n",
    "    resultDutWords_line_no = assign_line_no(result_dut)\n",
    "    dutchWord_line_no = assign_line_no(dut_cleaned)\n",
    "\n",
    "    tf_of_cleaned = maintain_count(dutchWord_line_no,dut_cleaned)\n",
    "    \n",
    "    tf_of_result = maintain_count(resultDutWords_line_no,result_dut)\n",
    "    \n",
    "    avg_cleaned = statistics.mean(tf_of_cleaned.values())\n",
    "    avg_result = statistics.mean(tf_of_result.values())\n",
    "    \n",
    "    for i in tf_of_cleaned.keys():\n",
    "        \n",
    "        total_sim += ((tf_of_cleaned[i]-avg_cleaned) * (tf_of_result[i] - avg_result))\n",
    "        \n",
    "    stddev_cleaned = statistics.stdev(tf_of_cleaned.values())\n",
    "    stddev_result = statistics.stdev(tf_of_result.values())\n",
    "    \n",
    "    return total_sim/(stddev_cleaned*stddev_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FEZe5h9ZdI6"
   },
   "source": [
    "Function to find cosine similarity between 2 documents\n",
    "    \n",
    "Required: Clean test data before calculating cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4E6qLha3RcKH"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(dut_cleaned,result_dut):\n",
    "    \n",
    "    resultDutWords_line_no = assign_line_no(result_dut)\n",
    "    dutchWord_line_no = assign_line_no(dut_cleaned)\n",
    "\n",
    "    tf_of_cleaned = maintain_normalized_tf(dutchWord_line_no,dut_cleaned)\n",
    "    \n",
    "    tf_of_result = maintain_normalized_tf(resultDutWords_line_no,result_dut)\n",
    "    \n",
    "    total_sim = 0\n",
    "    \n",
    "    for i in tf_of_cleaned.keys():\n",
    "        total_sim += tf_of_cleaned[i] * tf_of_result[i]\n",
    "        \n",
    "    return total_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0ILDqY_Zn4Q"
   },
   "source": [
    "Function to find normalized term-frequency of a word in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qLpFNRORcKL"
   },
   "outputs": [],
   "source": [
    "def maintain_normalized_tf(doc_dict_line_no, data_clean):\n",
    "    \n",
    "    og_dutch_tf = {}\n",
    "    \n",
    "    sum_of_tf = 0\n",
    "    \n",
    "    for dword in doc_dict_line_no:                #for each word in the document\n",
    "        dlist=[]\n",
    "        dlist=list(doc_dict_line_no[dword])\n",
    "        count = 0\n",
    "        for i in dlist:\n",
    "            count+= dut_cleaned[i].count(dword)\n",
    "        \n",
    "        og_dutch_tf[dword] = math.log(count)+1\n",
    "        sum_of_tf += pow(og_dutch_tf[dword],2)\n",
    "    \n",
    "    normalized_denom = pow(sum_of_tf,0.5)\n",
    "    \n",
    "    for i in og_dutch_tf.keys():\n",
    "        og_dutch_tf[i] = og_dutch_tf[i]/normalized_denom\n",
    "\n",
    "        \n",
    "    return og_dutch_tf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kc4mglD6Zp_3"
   },
   "source": [
    "Function to translate a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mt0GerzRcKQ"
   },
   "outputs": [],
   "source": [
    "def produce_sentence(eng_sentence, translated_dict,doc_lang):\n",
    "\n",
    "    \n",
    "    s = \"\"\n",
    "\n",
    "    a = [ ':','.' , '\\\\' , '/' , ',' , ';' , '(' , ')' , '\"', \"\\'\",'1','2','3','4','5','6','7','8','9','0','?']\n",
    "    \n",
    "    for i in eng_sentence:\n",
    "        if i in a:\n",
    "            s+=i\n",
    "            continue\n",
    "            \n",
    "        s += str(tr[i])\n",
    "    \n",
    "    s+='\\n'\n",
    "    \n",
    "    return s\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YJzBDgdZ1MH"
   },
   "source": [
    "  Function to translate a document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6cpIkMQRcKW"
   },
   "outputs": [],
   "source": [
    "def translate_doc(eng_doc, translated_dict, rewrite_file, doc_lang = 'eng'):\n",
    "   \n",
    "    result_doc = []\n",
    "    \n",
    "    for i in eng_doc:\n",
    "        s = produce_sentence(i, translated_dict,doc_lang)\n",
    "        result_doc.append(s)\n",
    "    \n",
    "    with open(rewrite_file,'w') as f:\n",
    "        f.writelines(result_doc)\n",
    "    \n",
    "    return result_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyv-mX0fZ9le"
   },
   "source": [
    "Deleting previously present files responsible for maintaining translational probabilities and count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iD3qYOFZRcKb"
   },
   "outputs": [],
   "source": [
    "def delete_files():\n",
    " \n",
    "    try:\n",
    "        os.remove(PROB_FILE)\n",
    "    except OSError as e:  ## if failed, report it back to the user ##\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    try:\n",
    "        os.remove(COUNT_FILE)\n",
    "    except OSError as e:  ## if failed, report it back to the user ##\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0hja_gnRcKg"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    \n",
    "    Eng_File = UPDATED_ENGLISH_FILE\n",
    "    Dutch_File = UPDATED_DUTCH_FILE\n",
    "    \n",
    "    eng_data, dutch_data = readfiles(Eng_File,Dutch_File,100)\n",
    "    \n",
    "    print(\"Files read\")\n",
    "    \n",
    "    # Cleaning Data\n",
    "    \n",
    "    eng_cleaned = remove_punc(eng_data,'eng')\n",
    "    dut_cleaned = remove_punc(dutch_data,'dutch')\n",
    "    \n",
    "    total_no_of_sentences = len(dut_cleaned)\n",
    "    \n",
    "    print(\"Files cleaned\")\n",
    "    \n",
    "    # Making dictionaries\n",
    "    \n",
    "    dutchWords_line_no = assign_line_no(dut_cleaned)\n",
    "    engWords_line_no = assign_line_no(eng_cleaned)\n",
    "    \n",
    "    #print(dutchWords_line_no)\n",
    "    \n",
    "    no_of_words_eng = len(engWords_line_no)\n",
    "    no_of_words_dutch = len(dutchWords_line_no)\n",
    "    \n",
    "    num_dict_eng = {}\n",
    "    num_dict_dutch = {}\n",
    "    \n",
    "    num_dict_dutch,num_dict_eng = initialize(no_of_words_dutch , dutchWords_line_no , engWords_line_no , num_dict_dutch , num_dict_eng)\n",
    "    \n",
    "    #assert(prob==True)\n",
    "    \n",
    "    print(\"Initialization Done\")\n",
    "    \n",
    "    running_function(dutchWords_line_no, engWords_line_no, dut_cleaned , eng_cleaned , total_no_of_sentences, num_dict_dutch,num_dict_eng,10)\n",
    "    \n",
    "    print(\"Model Trained\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    tr_etof, tr_ftoe = retrieve_max(dutchWords_line_no,engWords_line_no,len(num_dict_dutch),num_dict_dutch,num_dict_eng)\n",
    "    \n",
    "    tr_etof.update(EngToDutchStopWords())\n",
    "    tr_ftoe.update(DutchToEngStopWords())\n",
    "    \n",
    "    print(tr_etof)\n",
    "    print(\"\\n\\n\\n\\n\")\n",
    "    print(tr_ftoe)\n",
    "    \n",
    "    with open('etof.json','w') as fp:\n",
    "        json.dump(tr_etof,fp)\n",
    "    \n",
    "    with open('ftoe.json','w') as fp:\n",
    "        json.dump(tr_ftoe,fp)\n",
    "    \n",
    "    #new_doc = open(TEST_FILE,'r+')\n",
    "    #lines = new_doc.readlines()\n",
    "    \n",
    "    #b = translate_doc(lines,tr_etof,TEST_FILE)\n",
    "    \n",
    "    #print(b)\n",
    "    \n",
    "    \n",
    "    #print(tr_etof)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LM1McijJRcKk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PROB_FILE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d8866397a008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdelete_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-41504fd31d70>\u001b[0m in \u001b[0;36mdelete_files\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPROB_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m## if failed, report it back to the user ##\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Error: %s - %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PROB_FILE' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ ==\"__main__\":\n",
    "    delete_files()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRU6wi7yRcKp"
   },
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_Y7zN55RcKt"
   },
   "outputs": [],
   "source": [
    "def Test_Main(to_be_translated , answer_key, lang):\n",
    "    \n",
    "    tr_etof.update(EngToDutchStopWords)\n",
    "    tr_ftoe.update(DutchToEngStopWords)\n",
    "    \n",
    "    rewrite_File = 'result.txt'\n",
    "    \n",
    "    if lang == 'eng':\n",
    "        result = translate_doc(to_be_translated,tr_etof, rewrite_File,'eng')\n",
    "    elif lang =='dutch':\n",
    "        result = translate_doc(to_be_translated,tr_ftoe, rewrite_File,'dutch')\n",
    "    \n",
    "    a_file = open(to_be_translated,'r+')\n",
    "    r_file = open(rewrite_File,'r+')\n",
    "    \n",
    "    an_data = a_file.readlines()\n",
    "    re_data = r_file.readlines()\n",
    "    \n",
    "    a_clean = remove_punctuations(og_data,lang)\n",
    "    r_clean = remove_punctuations(og_data,lang)\n",
    "    \n",
    "    print(pearson_coefficient(r_clean,a_clean))\n",
    "    print(cosine_similarity(r_clean,a_clean))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_punctuations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-c6421f252e91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0man_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mre_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0ma_clean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_punctuations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mog_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mr_clean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_punctuations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mog_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpearson_coefficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_clean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma_clean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'remove_punctuations' is not defined"
     ]
    }
   ],
   "source": [
    "to_be_translated=\"to_be_translated.txt\"\n",
    "r_clean = remove_punctuations(og_data,lang)\n",
    "pearson_coefficient(r_clean,a_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Final_IBM_Model1_File_Handling(4).ipynb",
   "provenance": [
    {
     "file_id": "0B2ern4F7TaVwRDJrV1VBejBmdUpPS1lZNWZGdmZ1Y1d4N3BN",
     "timestamp": 1573174781687
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
