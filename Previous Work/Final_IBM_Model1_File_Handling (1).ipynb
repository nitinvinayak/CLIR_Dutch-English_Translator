{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import sqlite3\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Files\n",
    "\n",
    "UPDATED_ENGLISH_FILE = 'English_Updated.txt'\n",
    "UPDATED_DUTCH_FILE = 'Dutch_Updated.txt'\n",
    "\n",
    "ENG_TEST_FILE = 'eng.txt'\n",
    "DUTCH_TEST_FILE = 'dutch.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('TransProb1.db')\n",
    "crsr = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_etof = {}\n",
    "tr_ftoe = {}\n",
    "#total = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Files\n",
    "\n",
    "PROB_FILE = 'condProb.txt'\n",
    "COUNT_FILE = 'count.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EngToDutchStopWords():\n",
    "    eng_sw=['of', 'the', 'I', 'on', 'and', 'would', 'to', 'you', 'a', 'in', 'that', 'as', 'have', 'for', 'be', 'from', 'it', 'at', 'can', 'an', 'has', 'The', 'It', 'is', 'not', 'with', 'We', 'by', 'This', 'we', 'are', 'more', 'our', 'or', 'also', 'these', 'but', 'must']\n",
    "    dut_sw=['van', 'de', 'ik', 'Aan', 'en', 'Zou', 'naar', 'u', 'een', 'in', 'dat', 'als', 'hebben', 'voor', 'worden', 'van', 'het', 'Bij', 'kan', 'een', 'heeft', 'De', 'Het', 'is', 'niet', 'met', 'Wij', 'door', 'Deze', 'wij', 'zijn', 'meer', 'onze', 'of', 'ook', 'deze', 'maar', 'moet']\n",
    "    \n",
    "    return(dict(zip(eng_sw, dut_sw)))\n",
    "\n",
    "def DutchToEngStopWords():\n",
    "    eng_sw=['of', 'the', 'I', 'on', 'and', 'would', 'to', 'you', 'a', 'in', 'that', 'as', 'have', 'for', 'be', 'from', 'it', 'at', 'can', 'an', 'has', 'The', 'It', 'is', 'not', 'with', 'We', 'by', 'This', 'we', 'are', 'more', 'our', 'or', 'also', 'these', 'but', 'must']\n",
    "    dut_sw=['van', 'de', 'ik', 'Aan', 'en', 'Zou', 'naar', 'u', 'een', 'in', 'dat', 'als', 'hebben', 'voor', 'worden', 'van', 'het', 'Bij', 'kan', 'een', 'heeft', 'De', 'Het', 'is', 'niet', 'met', 'Wij', 'door', 'Deze', 'wij', 'zijn', 'meer', 'onze', 'of', 'ook', 'deze', 'maar', 'moet']\n",
    "    \n",
    "    return(dict(zip( dut_sw,eng_sw)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfiles(Eng_File, Dutch_File,no_of_sentences):\n",
    "    \"\"\"\n",
    "    Function to read required number of lines(no_of_sentences) from given text files  \n",
    "    \n",
    "    \"\"\"\n",
    "    e_file = open(Eng_File,'r',encoding = 'utf-8')\n",
    "    d_file = open(Dutch_File,'r',encoding = 'utf-8')\n",
    "    \n",
    "    dutch = d_file.readlines()[:no_of_sentences]\n",
    "    eng = e_file.readlines()[:no_of_sentences]\n",
    "    \n",
    "    return eng, dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_no_of_sentences = len(dutch) # or len(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(l,lang):\n",
    "    \"\"\"\n",
    "    Function to remove punctuation symbols from acquired sentences\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(l)):\n",
    "        l[i] = l[i][:-1].lower()\n",
    "        l[i] = remove_stopwords(l[i],lang)\n",
    "        l[i] = remove_stuff(l[i])\n",
    "    return l\n",
    "\n",
    "def remove_stopwords(l,lang):\n",
    "    eng_sw=['of', 'the', 'I', 'on', 'and', 'would', 'to', 'you', 'a', 'in', 'that', 'as', 'have', 'for', 'be', 'from', 'it', 'at', 'can', 'an', 'has', 'The', 'It', 'is', 'not', 'with', 'We', 'by', 'This', 'we', 'are', 'more', 'our', 'or', 'also', 'these', 'but', 'must']\n",
    "    dut_sw=['van', 'de', 'ik', 'Aan', 'en', 'Zou', 'naar', 'u', 'een', 'in', 'dat', 'als', 'hebben', 'voor', 'worden', 'van', 'het', 'Bij', 'kan', 'een', 'heeft', 'De', 'Het', 'is', 'niet', 'met', 'Wij', 'door', 'Deze', 'wij', 'zijn', 'meer', 'onze', 'of', 'ook', 'deze', 'maar', 'moet']\n",
    "    \n",
    "    words = l.split()\n",
    "    s = []\n",
    "    \n",
    "    if lang =='dutch':\n",
    "        for i in words:\n",
    "            if i not in dut_sw:\n",
    "                s.append(i)\n",
    "    elif lang =='eng':\n",
    "        for i in words:\n",
    "            if i not in eng_sw:\n",
    "                s.append(i)\n",
    "    return ' '.join(s)\n",
    "    \n",
    "def remove_stuff(l):\n",
    "    a = [ ':','.' , '\\\\' , '/' , ',' , ';' , '(' , ')' , '\"', \"\\'\",'1','2','3','4','5','6','7','8','9','0','?']\n",
    "    for i in a:\n",
    "        l = l.replace(i, \"\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(l,lang):\n",
    "    \"\"\"\n",
    "    Function to remove punctuation symbols from acquired sentences\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(l)):\n",
    "        l[i] = l[i][:-1].lower()\n",
    "        l[i] = remove_stuff(l[i])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# After cleaning files\\n\\ndutch2 = remove_punc(dutch)\\neng2 = remove_punc(eng)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# After cleaning files\n",
    "\n",
    "dutch2 = remove_punc(dutch)\n",
    "eng2 = remove_punc(eng)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dutchWords_line_no = defaultdict(set)\\nengWords_line_no = defaultdict(set)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dutchWords_line_no = defaultdict(set)\n",
    "engWords_line_no = defaultdict(set)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_line_no(doc):\n",
    "    dict_lo = defaultdict(set)\n",
    "    for i in range(len(doc)):\n",
    "        t = doc[i].split()\n",
    "        for m in t:\n",
    "            dict_lo[m].add(i)\n",
    "    return dict_lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dutchWords_line_no = assign_line_no(dutch2)\\nengWords_line_no = assign_line_no(eng2)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dutchWords_line_no = assign_line_no(dutch2)\n",
    "engWords_line_no = assign_line_no(eng2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no_of_words_eng = len(engWords_line_no)\\nno_of_words_dutch = len(dutchWords_line_no)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"no_of_words_eng = len(engWords_line_no)\n",
    "no_of_words_dutch = len(dutchWords_line_no)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(no_of_words_eng)\\nprint(no_of_words_dutch)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(no_of_words_eng)\n",
    "print(no_of_words_dutch)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict_dutch(foreign_l,num_dict_dutch):\n",
    "    \"\"\"\n",
    "    Function to create an indexed dictionary of dutch words \n",
    "    \n",
    "    \"\"\"\n",
    "    c=1\n",
    "    for i in foreign_l.keys():\n",
    "        num_dict_dutch[i]=c\n",
    "        c+=1\n",
    "    return num_dict_dutch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###REPALCE\n",
    "def initialize(foreign_no_of_words,foreign_l,english_l,num_dict_dutch,num_dict_eng):\n",
    "    \"\"\"\n",
    "    Function to create pairs of English and Dutch words, and initializing their probabilities uniformly\n",
    "    \"\"\"\n",
    "    probabilities = {} # Initializing proablities\n",
    "    index = -1*(foreign_no_of_words)\n",
    "    counter = 0\n",
    "    \n",
    "    num_dict_dutch = make_dict_dutch(foreign_l,num_dict_dutch)\n",
    "    init_prob = 1/foreign_no_of_words\n",
    "    \n",
    "    for i in english_l.keys():\n",
    "        num_dict_eng[i]=index+foreign_no_of_words\n",
    "        index=index+foreign_no_of_words\n",
    "    \n",
    "    return num_dict_dutch, num_dict_eng\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_dict_eng = {}\\nnum_dict_dutch={}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"num_dict_eng = {}\n",
    "num_dict_dutch={}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPLACE\n",
    "def write_to_file(probabilities,english_word,counter,file_name,foreign_no_of_words,index,num_dict_eng):\n",
    "    \"\"\"\n",
    "    Function to write probabilities of english-dutch pairs to a file\n",
    "    \"\"\"\n",
    "    #file = open(file_name,'a')\n",
    "    num_dict_eng[english_word]=index+foreign_no_of_words\n",
    "    index=index+foreign_no_of_words\n",
    "    '''for k,v in probabilities.items():\n",
    "        file.write('{0} {1}\\n'.format(k,v))\n",
    "    file.close()\n",
    "    '''\n",
    "    return index, num_dict_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t = time.process_time()\\nprob = initialize(no_of_words_dutch,dutchWords_line_no,engWords_line_no,num_dict_dutch,num_dict_eng)\\nelapsed_time = time.process_time() - t\\nprint(elapsed_time)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"t = time.process_time()\n",
    "prob = initialize(no_of_words_dutch,dutchWords_line_no,engWords_line_no,num_dict_dutch,num_dict_eng)\n",
    "elapsed_time = time.process_time() - t\n",
    "print(elapsed_time)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_probabilities(dutch_sentences, eng_sentences,no_of_sentences,total,num_dict_dutch,num_dict_eng,count_file):\n",
    "    \"\"\"\n",
    "    Function to update count for each english-dutch pair\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(no_of_sentences):\n",
    "        \n",
    "        \n",
    "        en = eng_sentences[i]\n",
    "        en_words = en.split()\n",
    "        \n",
    "\n",
    "        du = dutch_sentences[i]\n",
    "        du_words = du.split()\n",
    "        \n",
    "\n",
    "        retrieved_count = {}\n",
    "        retrieved_term_probability = {}\n",
    "\n",
    "        for e in en_words:\n",
    "\n",
    "            for d in du_words:\n",
    "\n",
    "                comm = \"select * from TransProb where ENG_WORD= '{0}' AND DUT_WORD= '{1}'\".format(e,d)\n",
    "                com2 = \"select * from Count where ENG_WORD= '{0}' AND DUT_WORD= '{1}'\".format(e,d)\n",
    "                \n",
    "                crsr.execute(comm)\n",
    "                ans = crsr.fetchall()\n",
    "                \n",
    "                crsr.execute(com2)\n",
    "                an2 = crsr.fetchall()\n",
    "                try:\n",
    "                    line_no2= ans[0][0]+'_'+ans[0][1]+' '+str(ans[0][2])\n",
    "                    line_no = an2[0][0]+'_'+an2[0][1]+' '+str(an2[0][2])\n",
    "                except:\n",
    "                    print(line_no2)\n",
    "                pr = line_no.split()\n",
    "                pr2 = line_no2.split()\n",
    "\n",
    "                retrieved_count[pr[0]] = float(pr[1])\n",
    "                retrieved_term_probability[pr2[0]] = float(pr2[1])\n",
    "              \n",
    "\n",
    "        print(\"Count and Translation probabilities retrieved\")\n",
    "        \n",
    "        print(retrieved_term_probability)\n",
    "\n",
    "        s_total = {}\n",
    "\n",
    "        for e in en_words:\n",
    "\n",
    "            s_total[e] = 0\n",
    "\n",
    "            for d in du_words:\n",
    "\n",
    "                s = e+'_'+d\n",
    "\n",
    "                s_total[e] += retrieved_term_probability[s]\n",
    "\n",
    "        print(s_total)\n",
    "        print(\"S_total for each english word done\")\n",
    "                \n",
    "        for e in en_words:\n",
    "\n",
    "            for d in du_words:\n",
    "\n",
    "                s = e+'_'+d\n",
    "\n",
    "                retrieved_count[s] += (retrieved_term_probability[s]/s_total[e])\n",
    "\n",
    "                total[d] += (retrieved_term_probability[s]/s_total[e])\n",
    "\n",
    "        print(\"Counts modified and Total calculated\")\n",
    "        \n",
    "        print(retrieved_count)\n",
    "        print()\n",
    "        print(retrieved_term_probability)\n",
    "        \n",
    "        \n",
    "        for k,v in retrieved_count.items():\n",
    "            \n",
    "            t = k.split('_')\n",
    "            e = k[0]\n",
    "            d = k[1]\n",
    "            \n",
    "            command= \"UPDATE Count SET PROBABILITY=\" + str(v) +\" WHERE ENG_WORD = '\" +str(e) + \"' AND DUT_WORD ='\"+str(d)+\"'\"\n",
    "            crsr.execute(command)\n",
    "                \n",
    "        con.commit()\n",
    "        \n",
    "        print(\"Writeback completed into count file\")\n",
    "        break\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_function(foreign_l, english_l, dutch_sentences, eng_sentences, no_of_sentences,num_dict_dutch,num_dict_eng,no_of_iterations=10):\n",
    "    \"\"\"\n",
    "    Function to reinitialize total for foreign words and count for eng-dutch pairs. It carries out (no_of_iterations) iterations\n",
    "    It rewrites the translational probabilities back into the CondProb file.\n",
    "    \"\"\"\n",
    "    loc =\"\"\n",
    "    \n",
    "    \n",
    "    for c_i in range(no_of_iterations):\n",
    "        \n",
    "        print(c_i+1)\n",
    "        \n",
    "        for i in english_l.keys():\n",
    "            for j in foreign_l.keys():\n",
    "                command= \"UPDATE Count SET PROBABILITY= {0} WHERE ENG_WORD = '{1}' AND DUT_WORD ='{2}' \".format(0,i,j)\n",
    "                crsr.execute(command)\n",
    "            con.commit()\n",
    "            \n",
    "                \n",
    "    \n",
    "        total = {}\n",
    "    \n",
    "        for k in foreign_l.keys():\n",
    "            total[k] = 0\n",
    "    \n",
    "        total = finding_probabilities(dutch_sentences,eng_sentences,no_of_sentences,total,num_dict_dutch,num_dict_eng,loc)\n",
    "    \n",
    "    \n",
    "        print(\"Finding probabilities done, \",c_i)\n",
    "        retrieved_count = {}\n",
    "        retrieved_term_probability = {}\n",
    "    \n",
    "        print(total)\n",
    "        \n",
    "        \n",
    "        for e in english_l.keys():\n",
    "            \n",
    "            for d in foreign_l.keys():\n",
    "                \n",
    "                dutch_line_no = num_dict_dutch[d]\n",
    "                \n",
    "                com2 = \"select * from Count where ENG_WORD= '{0}' AND DUT_WORD= '{1}'\".format(e,d)\n",
    "                crsr.execute(com2)\n",
    "                ans = crsr.fetchall()\n",
    "                \n",
    "                try:\n",
    "                    line_no = ans[0][0]+'_'+ans[0][1]+' '+str(ans[0][2])\n",
    "                except:\n",
    "                    print(line_no)\n",
    "                \n",
    "                pr = line_no.split()\n",
    "                \n",
    "                retrieved_count[pr[0]] = float(pr[1])\n",
    "            con.commit()\n",
    "        \n",
    "    \n",
    "\n",
    "        print(\"Counts, retrieved\")\n",
    "        \n",
    "        print()\n",
    "        print(retrieved_count)\n",
    "    \n",
    "        for d in foreign_l.keys():\n",
    "            for e in english_l.keys():\n",
    "            \n",
    "                s = e+ '_' +d\n",
    "                retrieved_term_probability[s] = retrieved_count[s]/total[d]  \n",
    "                \n",
    "                \n",
    "                command= \"UPDATE TransProb SET PROBABILITY= {0} WHERE ENG_WORD = '{1}' AND DUT_WORD ='{2}' \".format(float(retrieved_term_probability[s]),e,d)\n",
    "                crsr.execute(command)\n",
    "                \n",
    "            con.commit()\n",
    "        \n",
    "        print(\"Translational Probabilites updated\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file2(probabilities,english_word,file_name,mode = 'a'):\n",
    "    \"\"\"\n",
    "    Function to write the counts into a file\n",
    "    \"\"\"\n",
    "    file = open(file_name,'a') \n",
    "    #file.write(str(counter)+' '+english_word+'\\n')\n",
    "    for k,v in probabilities.items():\n",
    "        file.write('{0} {1}\\n'.format(k,v))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t = time.process_time()\\nrunning_function(dutchWords_line_no,engWords_line_no,dutch2,eng2,total_no_of_sentences)\\nelapsed_time = time.process_time() - t\\nprint(elapsed_time)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"t = time.process_time()\n",
    "running_function(dutchWords_line_no,engWords_line_no,dutch2,eng2,total_no_of_sentences)\n",
    "elapsed_time = time.process_time() - t\n",
    "print(elapsed_time)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_max(foreign_l,english_l,no_of_dutch_words,num_dict_dutch,num_dict_eng):\n",
    "    \"\"\"\n",
    "    Function to retieve the translaton with maximum probabilities for each word to be translated, i.e. to obtain the most probable translation for each word.     \n",
    "    \"\"\"\n",
    "    translation_etof = {}\n",
    "    translation_ftoe = {}\n",
    "    \n",
    "    for e in english_l.keys():\n",
    "        \n",
    "        #print(e,counter)\n",
    "        \n",
    "        comm = \"SELECT MAX(PROBABILITY),DUT_WORD From TransProb where ENG_WORD = '{0}'\".format(e)\n",
    "        \n",
    "        crsr.execute(comm)\n",
    "        \n",
    "        ans = crsr.fetchall()\n",
    "         \n",
    "        translation_etof[e] = ans[0][1]\n",
    "        translation_ftoe[ans[0][1]] = e\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    return translation_etof,translation_ftoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_coefficient(dut_cleaned,result_dut):\n",
    "    \"\"\"\n",
    "    Function to find Pearson Coefficient\n",
    "    \"\"\"\n",
    "    \n",
    "    resultDutWords_line_no = assign_line_no(result_dut)\n",
    "    dutchWord_line_no = assign_line_no(dut_cleaned)\n",
    "\n",
    "    tf_of_cleaned = maintain_count(dutchWord_line_no,dut_cleaned)\n",
    "    \n",
    "    tf_of_result = maintain_count(resultDutWords_line_no,result_dut)\n",
    "    \n",
    "    avg_cleaned = statistics.mean(tf_of_cleaned.values())\n",
    "    avg_result = statistics.mean(tf_of_result.values())\n",
    "    \n",
    "    for i in tf_of_cleaned.keys():\n",
    "        \n",
    "        total_sim += ((tf_of_cleaned[i]-avg_cleaned) * (tf_of_result[i] - avg_result))\n",
    "        \n",
    "    stddev_cleaned = statistics.stdev(tf_of_cleaned.values())\n",
    "    stddev_result = statistics.stdev(tf_of_result.values())\n",
    "    \n",
    "    return total_sim/(stddev_cleaned*stddev_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(dut_cleaned,result_dut):\n",
    "    \"\"\"\n",
    "    Function to find cosine similarity between 2 documents\n",
    "    \n",
    "    Required: Clean test data before calculating cosine_similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    resultDutWords_line_no = assign_line_no(result_dut)\n",
    "    dutchWord_line_no = assign_line_no(dut_cleaned)\n",
    "\n",
    "    tf_of_cleaned = maintain_normalized_tf(dutchWord_line_no,dut_cleaned)\n",
    "    \n",
    "    tf_of_result = maintained_normalized_tf(resultDutWords_line_no,result_dut)\n",
    "    \n",
    "    total_sim = 0\n",
    "    \n",
    "    for i in tf_of_cleaned.keys():\n",
    "        total_sim += tf_of_cleaned[i] * tf_of_result[i]\n",
    "        \n",
    "    return total_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maintain_normalized_tf(doc_dict_line_no, data_clean):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to find normalized term-frequency of a word in a document.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    og_dutch_tf = {}\n",
    "    \n",
    "    sum_of_tf = 0\n",
    "    \n",
    "    for dword in doc_dict_line_no:                #for each word in the document\n",
    "        dlist=[]\n",
    "        dlist=list(doc_dict_line_no[dword])\n",
    "        count = 0\n",
    "        for i in dlist:\n",
    "            count+= dut_cleaned[i].count(dword)\n",
    "        \n",
    "        og_dutch_tf[dword] = math.log(count)+1\n",
    "        sum_of_tf += pow(og_dutch_tf[dword],2)\n",
    "    \n",
    "    normalized_denom = pow(sum_of_tf,0.5)\n",
    "    \n",
    "    for i in og_dutch_tf.keys():\n",
    "        og_dutch_tf[i] = og_dutch_tf[i]/normalized_denom\n",
    "\n",
    "        \n",
    "    return og_dutch_tf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t = time.process_time()\\ntr = retrieve_max(dutchWords_line_no,engWords_line_no,len(num_dict_dutch))\\nelapsed_time = time.process_time() - t\\nprint(elapsed_time)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"t = time.process_time()\n",
    "tr = retrieve_max(dutchWords_line_no,engWords_line_no,len(num_dict_dutch))\n",
    "elapsed_time = time.process_time() - t\n",
    "print(elapsed_time)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_sentence(eng_sentence, translated_dict,doc_lang):\n",
    "    \"\"\"\n",
    "    Function to translate a sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = \"\"\n",
    "\n",
    "    a = [ ':','.' , '\\\\' , '/' , ',' , ';' , '(' , ')' , '\"', \"\\'\",'1','2','3','4','5','6','7','8','9','0','?']\n",
    "    \n",
    "    for i in eng_sentence:\n",
    "        if i in a:\n",
    "            s+=i\n",
    "            continue\n",
    "            \n",
    "        s += str(tr[i])\n",
    "    \n",
    "    s+='\\n'\n",
    "    \n",
    "    return s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_doc(eng_doc, translated_dict, rewrite_file, doc_lang = 'eng'):\n",
    "    \"\"\"\n",
    "    Function to translate a document.\n",
    "    \"\"\"\n",
    "    \n",
    "    result_doc = []\n",
    "    \n",
    "    for i in eng_doc:\n",
    "        s = produce_sentence(i, translated_dict,doc_lang)\n",
    "        result_doc.append(s)\n",
    "    \n",
    "    with open(rewrite_file,'w') as f:\n",
    "        f.writelines(result_doc)\n",
    "    \n",
    "    return result_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files():\n",
    "    \"\"\"\n",
    "    Deleting previously present files responsible for maintaining translational probabilities and count.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.remove(PROB_FILE)\n",
    "    except OSError as e:  ## if failed, report it back to the user ##\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    try:\n",
    "        os.remove(COUNT_FILE)\n",
    "    except OSError as e:  ## if failed, report it back to the user ##\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    Eng_File = UPDATED_ENGLISH_FILE\n",
    "    Dutch_File = UPDATED_DUTCH_FILE\n",
    "    \n",
    "    eng_data, dutch_data = readfiles(Eng_File,Dutch_File,100)\n",
    "    \n",
    "    print(\"Files read\")\n",
    "    \n",
    "    # Cleaning Data\n",
    "    \n",
    "    eng_cleaned = remove_punc(eng_data,'eng')\n",
    "    dut_cleaned = remove_punc(dutch_data,'dutch')\n",
    "    \n",
    "    total_no_of_sentences = len(dut_cleaned)\n",
    "    \n",
    "    print(\"Files cleaned\")\n",
    "    \n",
    "    # Making dictionaries\n",
    "    \n",
    "    dutchWords_line_no = assign_line_no(dut_cleaned)\n",
    "    engWords_line_no = assign_line_no(eng_cleaned)\n",
    "    \n",
    "    #print(dutchWords_line_no)\n",
    "    \n",
    "    no_of_words_eng = len(engWords_line_no)\n",
    "    no_of_words_dutch = len(dutchWords_line_no)\n",
    "    \n",
    "    num_dict_eng = {}\n",
    "    num_dict_dutch = {}\n",
    "    \n",
    "    num_dict_dutch,num_dict_eng = initialize(no_of_words_dutch , dutchWords_line_no , engWords_line_no , num_dict_dutch , num_dict_eng)\n",
    "    \n",
    "    #assert(prob==True)\n",
    "    \n",
    "    print(\"Initialization Done\")\n",
    "    \n",
    "    running_function(dutchWords_line_no, engWords_line_no, dut_cleaned , eng_cleaned , total_no_of_sentences, num_dict_dutch,num_dict_eng,10)\n",
    "    \n",
    "    print(\"Model Trained\")\n",
    "    \n",
    "    tr_etof, tr_ftoe = retrieve_max(dutchWords_line_no,engWords_line_no,len(num_dict_dutch),num_dict_dutch,num_dict_eng)\n",
    "    \n",
    "    new_doc = open(TEST_FILE,'r+')\n",
    "    lines = new_doc.readlines()\n",
    "    \n",
    "    b = translate_doc(lines,tr_etof,TEST_FILE)\n",
    "    \n",
    "    print(b)\n",
    "    \n",
    "    \n",
    "    #print(tr_etof)    \n",
    "    '''\n",
    "    while(True):\n",
    "    \n",
    "        t = input(\"Do you want to delete all resulting files\")\n",
    "        if (t=='yes' or t == 'y' or t=='Yes' or t == 'Y'):\n",
    "            delete_files()\n",
    "            break\n",
    "        \n",
    "        elif (t=='No' or t=='N' or t=='n' or t=='no'):\n",
    "            break\n",
    "        \n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ ==\"__main__\":\n",
    "    delete_files()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, the remaining stuff:\n",
    "<ul>\n",
    "    <li>README FILE\n",
    "    <li>DOCUMENTATION\n",
    "    <li>SQL INTEGRATION\n",
    "    <li>DICTIONARY FOR STOPWORDS\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_Main(to_be_translated , answer_key, lang):\n",
    "    \n",
    "    tr_etof.update(EngToDutchStopWords)\n",
    "    tr_ftoe.update(DutchToEngStopWords)\n",
    "    \n",
    "    rewrite_File = 'result.txt'\n",
    "    \n",
    "    if lang == 'eng':\n",
    "        result = translate_doc(to_be_translated,tr_etof, rewrite_File,'eng')\n",
    "    elif lang =='dutch':\n",
    "        result = translate_doc(to_be_translated,tr_ftoe, rewrite_File,'dutch')\n",
    "    \n",
    "    a_file = open(to_be_translated,'r+')\n",
    "    r_file = open(rewrite_File,'r+')\n",
    "    \n",
    "    an_data = a_file.readlines()\n",
    "    re_data = r_file.readlines()\n",
    "    \n",
    "    a_clean = remove_punctuations(og_data,lang)\n",
    "    r_clean = remove_punctuations(og_data,lang)\n",
    "    \n",
    "    print(pearson_coefficient(r_clean,a_clean))\n",
    "    print(cosine_similarity(r_clean,a_clean))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
